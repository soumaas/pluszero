## 問２
### (1)機械学習で用いられるデータセットの一つに各アヤメの個体の大きさなどのデータとその個体の花の種類がまとめられたiris datasetがあります。iris datasetに欠損値がないと仮定します。sepal length(ガクの長さ)、sepal width(ガクの幅)、petal length(花弁の長さ)、petal length(花弁の幅)という連続値の特徴量からカテゴリ値を予測する機械学習モデルを考えます。ロジスティック回帰以外に考えられるアルゴリズムとその概要をmarkdown記法の箇条書きで3つ答えてください。そのアルゴリズムが教師あり学習かどうかも答えてください。

- ニューラルネットワーク 教師あり学習

- SVM 教師あり学習

- 決定木 教師あり学習

### (2.1) numpy_1d_array、numpy_2d_array_X_newを作成せよ。

//コード
```python
import numpy as np
import pandas as pd
from sklearn.datasets import load_iris

#numpy_1d_arrayを作成する
iris_dataset = load_iris()

X = iris_dataset['data']
y = iris_dataset['target']

numpy_1d_array　=　y

for i in range(len(y)):
   numpy_1d_array[i]=1
```
//実行結果
```
array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
```
//コード
``` python 
#numpy_2d_array_X_newを作成する
columns_name=["x0",'x1',"x2","x3","x4"]

numpy_2d_array_X_new=pd.DataFrame(X)
numpy_2d_array_X_new.insert(0,"x0",numpy_1d_array)
numpy_2d_array_X_new.set_axis(columns_name,axis=1,inplace=True)
numpy_2d_array_X_new
```
//実行結果
``` 
    x0	 x1	 x2	 x3	 x4
0	1	5.1	3.5	1.4	0.2
1	1	4.9	3.0	1.4	0.2
2	1	4.7	3.2	1.3	0.2
3	1	4.6	3.1	1.5	0.2
4	1	5.0	3.6	1.4	0.2
...	...	...	...	...	...
145	1	6.7	3.0	5.2	2.3
146	1	6.3	2.5	5.0	1.9
147	1	6.5	3.0	5.2	2.0
148	1	6.2	3.4	5.4	2.3
149	1	5.9	3.0	5.1	1.8
150 rows × 5 columns
```

### (3.2)1d array xと1d array bを引数として、(2)のロジスティック回帰モデルと同様な関数f(x, b)をつくってください。次に乱数を使って要素数5の1d array bを生成してください。乱数生成に使った確率分布とそのパラメータをmarkdown記法で書いておいてください。f(x, b)をX_new、bに適用し、ロジスティック回帰モデルの出力y_predを計算ください。

コード
```python
#ロジスティック回帰モデルと同様な関数f(x, b)
def logistic_regression(x,b):
    y_pred=1/(1+np.exp(np.dot(-b.T,x)))
    return y_pred
```
コード 

正規分布の乱数生成 平均0、分散1を使用
```python
_1d_array_b=np.random.randn(5)
_1d_array_b
```
実行結果
```
array([ 1.47013715, -0.59709285,  0.02475918, -1.8098367 , -1.08064008])
```
コード
```python
X_new=numpy_2d_array_X_new[:5]
X_new
```
実行結果
```
    x0	 x1  x2	 x3	 x4
0	1	5.1	3.5	1.4	0.2
1	1	4.9	3.0	1.4	0.2
2	1	4.7	3.2	1.3	0.2
3	1	4.6	3.1	1.5	0.2
4	1	5.0	3.6	1.4	0.2
```

コード
```
y_pred=logistic_regression(X_new,_1d_array_b)
y_pred
```
実行結果
```
array([1.19974327e-01, 1.18540589e-04, 2.31190875e-03, 4.86512964e-02,
       4.01664454e-01])
```

### (3.3)load_iris()で得られたyは各要素が0、1、2のいずれかになっていて花の種類のラベルを表しています。一方でy_predは[0,1]の連続値なので直接比較ができません。y_predと比較できるようにするためにyをどのようにすれば良いでしょうか

yをone-hot-encodingする。


### (4)これまででロジスティック回帰モデルの出力y_predと正解データy_labelが得られました。機械学習を用いたプロジェクトではこれからより正解に近いy_predが得られるようにbを最適化する必要があります。bを最適化する際に損失関数を最小化するとしましょう。ロジスティック回帰においてよく用いられる損失関数をmarkdown記法を用いて数式で表してください。またbを最適化する方法としてどのようなものが考えられるでしょうか

bも重さと同様に変数として扱い、勾配を加える


$$ H(p, q) = -\sum_{x} p(x) log(q(x)) $$


(5) (4)の最適化法を今手元にあるデータ全てを用いて行うとどのような弊害が考えられるでしょうか。またそうした弊害を避ける方法としてどのようなものがありますか。

弊害
trainデータに対してfitしすぎてしまい、テストデータに対する汎化性能が下がってしまう

対策
trainデータとvalidデータとtestデータに分けて学習を行う